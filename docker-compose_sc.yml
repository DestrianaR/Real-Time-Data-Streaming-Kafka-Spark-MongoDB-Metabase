version: '3.7'

services:
  zookeeper:
    image: bitnami/zookeeper:latest
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    networks:
      - my_network

  kafka1:
    image: bitnami/kafka:latest
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_HOST://:29092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:29092
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    ports:
      - "29092:29092"
    depends_on:
      - zookeeper
    networks:
      - my_network

  kafka2:
    image: bitnami/kafka:latest
    environment:
      - KAFKA_BROKER_ID=2
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9093,PLAINTEXT_HOST://:29093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:9093,PLAINTEXT_HOST://localhost:29093
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    ports:
      - "29093:29093"
    depends_on:
      - zookeeper
    networks:
      - my_network
  
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8085:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - my_network

  spark-master:
    build: ./spark_stream/scala_spark
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
    networks:
      - my_network
  
  spark-worker1:
    build: ./spark_stream/scala_spark
    container_name: spark-worker1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    networks:
      - my_network
  
  spark-worker2:
    build: ./spark_stream/scala_spark
    container_name: spark-worker2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    networks:
      - my_network

  # postgres:
  #   image: postgres:latest
  #   container_name: metabase-postgres
  #   environment:
  #     POSTGRES_USER: metabase
  #     POSTGRES_PASSWORD: metabase
  #     POSTGRES_DB: metabase
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #   networks:
  #     - my_network

  mongo:
    image: mongo:latest
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
      - ./init-db/mongo_init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
      MONGO_INITDB_DATABASE: db
    networks:
      - my_network

  # metabase:
  #   image: metabase/metabase:latest
  #   container_name: metabase
  #   hostname: metabase
  #   volumes:
  #     - /dev/urandom:/dev/random:ro
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     MB_DB_TYPE: postgres
  #     MB_DB_DBNAME: metabase
  #     MB_DB_PORT: 5432
  #     MB_DB_USER: metabase
  #     MB_DB_PASS: metabase
  #     MB_DB_HOST: postgres
  #   healthcheck:
  #     test: curl --fail -I http://localhost:3000/api/health || exit 1
  #     interval: 15s
  #     timeout: 5s
  #     retries: 5
  #   depends_on:
  #     - postgres
  #     - mongo
  #   networks:
  #   - my_network

volumes:
  # postgres_data:
  mongo_data:

networks:
  my_network: